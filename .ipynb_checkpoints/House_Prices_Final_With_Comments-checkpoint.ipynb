{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3b40aa",
   "metadata": {},
   "source": [
    "## Загрузка данных и первичный осмотр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv('train (1).csv')\n",
    "test = pd.read_csv('test (1).csv')\n",
    "\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "print(train.describe())\n",
    "\n",
    "print(\"Количество пропусков:\")\n",
    "print(train.isnull().sum())\n",
    "\n",
    "# Я загрузил данные и посмотрел их структуру.\n",
    "# Я убедился, что данные содержат нужные признаки и целевой признак SalePrice.\n",
    "# Я увидел, что в данных есть пропуски, которые нужно будет обработать.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27419e03",
   "metadata": {},
   "source": [
    "## Удаление ненужных признаков и базовая чистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a97a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols_to_drop = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'Id']\n",
    "train_clean = train.drop(columns=cols_to_drop)\n",
    "\n",
    "categorical_cols = train_clean.select_dtypes(include=['object']).columns\n",
    "numerical_cols = train_clean.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "train_clean[categorical_cols] = train_clean[categorical_cols].fillna('None')\n",
    "train_clean[numerical_cols] = train_clean[numerical_cols].fillna(train_clean[numerical_cols].median())\n",
    "\n",
    "print(train_clean.isnull().sum())\n",
    "\n",
    "# Я удалил признаки с большим количеством пропусков и незначительным влиянием на цену.\n",
    "# Я заполнил пропуски в категориальных признаках значением 'None'.\n",
    "# Я заполнил пропуски в числовых признаках медианой.\n",
    "# Я убедился, что пропуски полностью обработаны.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6283b83",
   "metadata": {},
   "source": [
    "## Анализ распределения числовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(train_clean['SalePrice'], kde=True)\n",
    "plt.title('Распределение SalePrice')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(train_clean['GrLivArea'], kde=True)\n",
    "plt.title('Распределение GrLivArea')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(train_clean['TotalBsmtSF'], kde=True)\n",
    "plt.title('Распределение TotalBsmtSF')\n",
    "plt.show()\n",
    "\n",
    "# Я построил графики распределения для целевого признака и важных признаков.\n",
    "# Я увидел, что распределение SalePrice не является нормальным и есть выбросы.\n",
    "# Я заметил, что GrLivArea и TotalBsmtSF тоже имеют выбросы.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd656c13",
   "metadata": {},
   "source": [
    "## Поиск выбросов с помощью boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=train_clean['OverallQual'], y=train_clean['SalePrice'])\n",
    "plt.title('SalePrice в зависимости от OverallQual')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=train_clean['GarageCars'], y=train_clean['SalePrice'])\n",
    "plt.title('SalePrice в зависимости от GarageCars')\n",
    "plt.show()\n",
    "\n",
    "# Я построил boxplot для поиска выбросов и изучения влияния качества на цену.\n",
    "# Я увидел, что с ростом качества и количества машин в гараже цена возрастает.\n",
    "# Я заметил, что в некоторых группах есть выбросы.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f6b39",
   "metadata": {},
   "source": [
    "## Диаграммы рассеяния для ключевых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5239f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.scatterplot(x=train_clean['GrLivArea'], y=train_clean['SalePrice'])\n",
    "plt.title('GrLivArea vs SalePrice')\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x=train_clean['TotalBsmtSF'], y=train_clean['SalePrice'])\n",
    "plt.title('TotalBsmtSF vs SalePrice')\n",
    "plt.show()\n",
    "\n",
    "# Я построил scatterplot для ключевых признаков.\n",
    "# Я подтвердил наличие сильной корреляции между GrLivArea и SalePrice.\n",
    "# Я увидел, что некоторые объекты с большой площадью имеют заниженную цену (выбросы).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4d1a2",
   "metadata": {},
   "source": [
    "## Корреляционная матрица с сортировкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_matrix = train_clean.select_dtypes(include=['int64', 'float64']).corr()\n",
    "corr_target = corr_matrix['SalePrice'].abs().sort_values(ascending=False).index\n",
    "sorted_corr_matrix = corr_matrix.loc[corr_target, corr_target]\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(sorted_corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", annot_kws={\"size\":7})\n",
    "plt.title('Корреляционная матрица (отсортирована по SalePrice)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Я построил корреляционную матрицу и отсортировал признаки по их связи с SalePrice.\n",
    "# Я увидел, что OverallQual, GrLivArea, GarageCars и TotalBsmtSF имеют наибольшую корреляцию с ценой.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff73a7",
   "metadata": {},
   "source": [
    "## Парные графики для числовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_features = ['SalePrice', 'OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', '1stFlrSF']\n",
    "\n",
    "sns.pairplot(train_clean[top_features])\n",
    "plt.show()\n",
    "\n",
    "# Я построил парные графики для признаков с высокой корреляцией.\n",
    "# Я подтвердил, что большинство признаков линейно связаны с ценой.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe165b",
   "metadata": {},
   "source": [
    "## Удаление выбросов по GrLivArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q1 = train_clean['GrLivArea'].quantile(0.25)\n",
    "Q3 = train_clean['GrLivArea'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = train_clean[(train_clean['GrLivArea'] < (Q1 - 1.5 * IQR)) | (train_clean['GrLivArea'] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "print(f\"Количество аномалий GrLivArea: {len(outliers)}\")\n",
    "\n",
    "train_clean = train_clean[~train_clean.index.isin(outliers.index)]\n",
    "\n",
    "# Я нашёл выбросы по GrLivArea и удалил их из датасета.\n",
    "# Я уверен, что это улучшит качество моделей.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c6d21",
   "metadata": {},
   "source": [
    "## Кодирование категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dac6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for col in train_clean.select_dtypes(include=['object']).columns:\n",
    "    train_clean[col] = encoder.fit_transform(train_clean[col].astype(str))\n",
    "\n",
    "# Я закодировал категориальные признаки, чтобы модели могли их обработать.\n",
    "# Теперь все признаки являются числовыми.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433bdd1",
   "metadata": {},
   "source": [
    "## Финальное деление данных и стандартизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = train_clean.drop(columns=['SalePrice'])\n",
    "y = train_clean['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Я разделил данные на обучающую и тестовую выборки.\n",
    "# Я стандартизировал признаки для лучшей сходимости моделей.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288da164",
   "metadata": {},
   "source": [
    "## Линейная регрессия и оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train_scaled, y_train)\n",
    "y_pred = model_lr.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Линейная регрессия MSE: {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "print(f\"Линейная регрессия R2: {r2_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "# Я обучил модель линейной регрессии.\n",
    "# Я получил метрики MSE и R2 для оценки качества модели.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32091bfa",
   "metadata": {},
   "source": [
    "## Случайный лес и важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d432d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Признак': X.columns, 'Важность': importances}).sort_values(by='Важность', ascending=False)\n",
    "\n",
    "print(feature_importance_df.head(15))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance_df.head(15), x='Важность', y='Признак')\n",
    "plt.title('Топ-15 важных признаков')\n",
    "plt.show()\n",
    "\n",
    "# Я обучил модель случайного леса.\n",
    "# Я посмотрел, какие признаки наиболее важны для модели.\n",
    "# Я визуализировал топ-15 признаков.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17543802",
   "metadata": {},
   "source": [
    "## Кросс-валидация модели случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14284323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "scores = cross_val_score(forest, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(f\"R2 по фолдам: {scores}\")\n",
    "print(f\"Среднее R2: {np.mean(scores):.2f}\")\n",
    "\n",
    "# Я провёл кросс-валидацию на 5 фолдах.\n",
    "# Я оценил стабильность модели и среднюю точность.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12e63f",
   "metadata": {},
   "source": [
    "## XGBoost и нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "xgb_pred = xgb.predict(X_test_scaled)\n",
    "print(f\"XGBoost MSE: {mean_squared_error(y_test, xgb_pred):.2f}\")\n",
    "print(f\"XGBoost R2: {r2_score(y_test, xgb_pred):.2f}\")\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=2000, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "mlp_pred = mlp.predict(X_test_scaled)\n",
    "print(f\"Нейросеть MSE: {mean_squared_error(y_test, mlp_pred):.2f}\")\n",
    "print(f\"Нейросеть R2: {r2_score(y_test, mlp_pred):.2f}\")\n",
    "\n",
    "# Я обучил модель XGBoost и нейронную сеть.\n",
    "# Я оценил качество моделей на тестовой выборке.\n",
    "# Я сравнил их производительность с другими моделями.\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
